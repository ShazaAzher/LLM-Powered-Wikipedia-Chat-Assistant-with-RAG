# LLM-Powered Wikipedia Chat Assistant with RAG

## Overview

This project focuses on building a conversational assistant powered by a Large Language Model (LLM) enhanced with Retrieval Augmented Generation (RAG) capabilities. By leveraging technologies like OpenAI, LlamaIndex, and Chainlit, we'll create an intelligent agent capable of accessing Wikipedia for information and engaging in real-time conversations.

## Features

- **Wikipedia Indexing**: Script to index Wikipedia pages in vector stores.
- **Semantic Search Tool**: Custom tool for semantic search within Wikipedia.
- **LLM-Powered Agent**: Intelligent agent using LLMs and ReAct framework for reasoning and action.
- **Conversational UI**: Interface for real-time interaction with the chat assistant.
- **Live Testing**: Ability to test the chat agent on live Wikipedia pages.

## Skills Required

- **Artificial Intelligence**: Understanding of AI concepts and models.
- **Interactive Real-time Web Applications**: Building applications with real-time interaction.
- **API Integration**: Integrating various APIs for functionality.
- **Front-end Development**: Creating user interfaces for interaction.
- **Python Programming**: Intermediate knowledge of object-oriented programming.

## Prerequisites

- Intermediate knowledge of Python programming.
- OpenAI access token (API Key).
- Understanding of ChatGPT or similar conversational AI tools.
- Familiarity with large language models.

## Technologies Used

- **OpenAI**: Leveraging OpenAI for large language model capabilities.
- **Python**: Programming language for development.
- **Pydantic**: Data validation and settings management library.
- **Chainlit**: Framework for creating conversational agents.
- **LlamaIndex**: Tool for indexing Wikipedia pages.

## Getting Started

To get started with this project, follow these steps:

1. Clone the repository from [https://github.com/ShazaAzher/LLM-Powered-Wikipedia-Chat-Assistant-with-RAG.git].
2. Install the necessary dependencies using pip.
3. Obtain an OpenAI access token.
4. Set up the required configurations.
5. Run the project and start interacting with the chat assistant.

